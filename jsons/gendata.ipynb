{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/pytorch/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]),\n",
    ")\n",
    "\n",
    "testing_data = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../easyFL/benchmark/cifar10/data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170499072it [05:43, 496158.13it/s]                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../easyFL/benchmark/cifar10/data/cifar-10-python.tar.gz to ../easyFL/benchmark/cifar10/data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.CIFAR10(\n",
    "    root=\"../easyFL/benchmark/cifar10/data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))]),\n",
    ")\n",
    "\n",
    "testing_data = datasets.CIFAR10(\n",
    "    root=\"../easyFL/benchmark/cifar10/data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "training_data = datasets.CIFAR100(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))]),\n",
    ")\n",
    "\n",
    "testing_data = datasets.CIFAR100(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Division algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Each client:**\n",
    "\n",
    "1. Contains no more than 3 labels\n",
    "2. Each label has 8 to 20 samples\n",
    "3. There're at least 5 * #numclass clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "total_labels = np.unique(training_data.targets).tolist()\n",
    "print(total_labels)\n",
    "\n",
    "alpha = 0.5\n",
    "\n",
    "min_sample_per_client = 15\n",
    "max_sample_per_client = 60\n",
    "\n",
    "num_clients = 20\n",
    "\n",
    "total_label = len(total_labels)\n",
    "label_list = [i for i in total_labels]\n",
    "\n",
    "labels = training_data.targets\n",
    "idxs = range(len(training_data))\n",
    "training_idxs_labels = np.vstack((idxs, labels)).T\n",
    "\n",
    "labels = testing_data.targets\n",
    "idxs = range(len(testing_data))\n",
    "testing_idxs_labels = np.vstack((idxs, labels)).T\n",
    "\n",
    "training_dict_client = {client_id:[] for client_id in range(num_clients)}\n",
    "testing_dict_client = {client_id:[] for client_id in range(num_clients)}\n",
    "\n",
    "label_dist = np.random.dirichlet([alpha/total_label for i in range(total_label)], num_clients)\n",
    "label_nums = np.zeros([num_clients, total_label])\n",
    "\n",
    "for client_idx in range(num_clients):\n",
    "    local_label_dist = label_dist[client_idx].tolist()\n",
    "    sample_this_client = np.random.randint(min_sample_per_client, max_sample_per_client + 1)\n",
    "    \n",
    "    for label, proportion in zip(label_list, local_label_dist):\n",
    "        sample_this_label = round(proportion * sample_this_client)\n",
    "        if sample_this_label > 0:\n",
    "            label_nums[client_idx, label] = sample_this_label\n",
    "            \n",
    "            idxes_1 = training_idxs_labels[training_idxs_labels[:,1] == label][:,0]\n",
    "            idxes_2 = testing_idxs_labels[testing_idxs_labels[:,1] == label][:,0]\n",
    "            \n",
    "            label_1_idxes = np.random.choice(idxes_1, sample_this_label, replace=False)\n",
    "            label_2_idxes = np.random.choice(idxes_2, max(5, int(np.ceil(sample_this_label/2))), replace=True)\n",
    "            \n",
    "            training_dict_client[client_idx] += label_1_idxes.tolist()\n",
    "            testing_dict_client[client_idx] += label_2_idxes.tolist()\n",
    "            \n",
    "            training_idxs_labels[label_1_idxes] -= 100\n",
    "            # testing_idxs_labels[label_2_idxes] -= 100\n",
    "\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\" Special json encoder for numpy types \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "    \n",
    "savepath = f\"./dataset_idx/cifar10/dirichlet/dir_{alpha}_sparse/{num_clients}client\"\n",
    "if not Path(savepath).exists():\n",
    "    os.makedirs(savepath)\n",
    "    \n",
    "json.dump(training_dict_client, open(f\"{savepath}/train.json\", \"w\"), cls=NumpyEncoder)\n",
    "json.dump(testing_dict_client, open(f\"{savepath}/test.json\", \"w\"), cls=NumpyEncoder)\n",
    "np.savetxt(f\"{savepath}/stats.csv\", label_nums, fmt=\"%d\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4dbc9917bcaa9a9fa434c727723b90f93ecc3435121eacd019fcd02c268a833c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
